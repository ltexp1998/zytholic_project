{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d64ad0ae",
   "metadata": {},
   "source": [
    "soup = BeautifulSoup(requests.get(\"http://beeradvocate.com/search?q=ipa&qt=beer\").content)\n",
    "\n",
    "# Find the beer links\n",
    "results = soup.findAll('div')\n",
    "\n",
    "# How many beers did it find\n",
    "beer_count = results[12].find('b').string.split(' ')[1]\n",
    "\n",
    "beer_links = results[13].findAll('li')\n",
    "links = []\n",
    "for link in beer_links:\n",
    "\tlinks.append(\"http://beeradvocate.com%s\" % (link.find('a')['href']))\n",
    "\n",
    "for beer in links:\n",
    "\tsoup = BeautifulSoup(requests.get(beer).content)\n",
    "\t\n",
    "\t# Beer name\n",
    "\tprint soup.find('h1', {'class': 'norm'}).string\n",
    "\t\n",
    "\t# Beer rating\n",
    "\tprint soup.find('span', {'class': 'BAscore_big'}).string"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd03b3bc",
   "metadata": {},
   "source": [
    "### Selenium file for scraping user reviews ###\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "driver = webdriver.Chrome('/Users/ltexp1998/code/ltexp1998/zytholic_project/notebooks/chromedriver')\n",
    "#open up the page\n",
    "driver.get('https://www.beeradvocate.com/beer/profile/29/1524/')\n",
    "\n",
    "#create the csv\n",
    "csv_file = open('nattyLight.csv', 'w')\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow(['date','attributes', 'rDev', 'name'])\n",
    "\n",
    "#to append to the original url\n",
    "url = '?view=beer&sort=&start='\n",
    "\n",
    "#find the number of reviews/last page\n",
    "last = driver.find_element_by_xpath('//*[@id=\"item_stats\"]/dl/dd[1]/span').text\n",
    "last = int(last.replace(',', ''))\n",
    "\n",
    "#name and brewery\n",
    "name = driver.find_element_by_xpath('//*[@id=\"content\"]/div/div/div[3]/div/div/div[1]/h1').text\n",
    "\n",
    "index = 0\n",
    "while index < last:\n",
    "    try:\n",
    "        print(str(index))\n",
    "        driver.get('https://www.beeradvocate.com/beer/profile/29/1524/' + url + str(index))\n",
    "        index = index + 25\n",
    "        reviews = driver.find_elements_by_xpath('//div[@id=\"rating_fullview\"]/div')\n",
    "        for review in reviews:\n",
    "                 rDict = {}\n",
    "                 name = name\n",
    "                 rDev = review.find_element_by_xpath('.//span[3]').text\n",
    "                 attributes = review.find_element_by_xpath('.//span[@class=\"muted\"]').text\n",
    "                 date = review.find_element_by_xpath('.//div//span[@class=\"muted\"]/a[2]').text\n",
    "                 \n",
    "\n",
    "                 rDict['name'] = name\n",
    "                 rDict['rDev'] = rDev\n",
    "                 rDict['attributes'] = attributes\n",
    "                 rDict['date'] = date\n",
    "                 writer.writerow(rDict.values())\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        csv_file.close()\n",
    "        driver.close()\n",
    "        break\n",
    "        \n",
    "        \n",
    "### Scrapy for tables on beer on Beeradvocate by style ###\n",
    "\n",
    "#spider\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from scrapy import Spider\n",
    "from scrapy.selector import Selector\n",
    "from demo.items import DemoItem\n",
    "\n",
    "class DemoSpider(Spider):\n",
    "    name = 'demo_spider'\n",
    "    allowed_urls = ['beeradvocate.com']\n",
    "    x = 'https://www.beeradvocate.com/beer/style/158/?sort=revsD&start='\n",
    "    start_urls = [x + str(i) for i in range(0,4519,50)]\n",
    "\n",
    "\n",
    "    def parse(self, response):\n",
    "        table = response.xpath('//*[@id=\"ba-content\"]/table/tr').extract()\n",
    "\n",
    "        for i in table:\n",
    "            Name = Selector(text=i).xpath('//*/td[1]/a/b/text()').extract()\n",
    "            Brewery = Selector(text=i).xpath('.//td[2]/a/text()').extract()\n",
    "            ABV = Selector(text=i).xpath('.//td[3]/span/text()').extract()\n",
    "            Avg = Selector(text=i).xpath('.//td[4]/b/text()').extract()\n",
    "            Ratings = Selector(text=i).xpath('.//td[5]/b/text()').extract()\n",
    "            Bros = Selector(text=i).xpath('.//td[6]/a/b/text()').extract()\n",
    "\n",
    "            item = DemoItem()\n",
    "            item['Name'] = Name\n",
    "            item['Brewery'] = Brewery\n",
    "            item['ABV'] = ABV\n",
    "            item['Avg'] = Avg\n",
    "            item['Ratings'] = Ratings\n",
    "            item['Bros'] = Bros\n",
    "\n",
    "            yield item\n",
    "\n",
    "#pipeline\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from scrapy.exporters import CsvItemExporter\n",
    "\n",
    "class BeerPipeline(object):\n",
    "\n",
    "        def __init__(self):\n",
    "                self.filename = 'beer.csv'\n",
    "\n",
    "        def open_spider(self, spider):\n",
    "                self.csvfile = open(self.filename, 'wb')\n",
    "                self.exporter = CsvItemExporter(self.csvfile)\n",
    "                self.exporter.start_exporting()\n",
    "\n",
    "        def close_spider(self, spider):\n",
    "                self.exporter.finish_exporting()\n",
    "                self.csvfile.close()\n",
    "\n",
    "        def process_item(self, item, spider):\n",
    "                self.exporter.export_item(item)\n",
    "                return item\n",
    "\n",
    "#items\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from scrapy import Item, Field\n",
    "\n",
    "class DemoItem(Item):\n",
    "    Style = Field()\n",
    "    Name = Field()\n",
    "    Brewery = Field()\n",
    "    ABV = Field()\n",
    "    Avg = Field()\n",
    "    Ratings = Field()\n",
    "    Bros = Field()\n",
    "\n",
    "#settings \n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "BOT_NAME = 'demo'\n",
    "\n",
    "SPIDER_MODULES = ['demo.spiders']\n",
    "NEWSPIDER_MODULE = 'demo.spiders'\n",
    "\n",
    "DOWNLOAD_DELAY = 3 #delay before changing URLs to avoid error \n",
    "\n",
    "ITEM_PIPELINES = {'demo.pipelines.BeerPipeline': 100, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff440954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
